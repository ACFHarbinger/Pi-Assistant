# RL PPO Mamba Preset
backbone: mamba
head: rl_policy
backbone_config:
  hidden_dim: 128
  num_layers: 4
  state_dim: 16
  dropout: 0.1
head_config:
  action_dim: 4
  continuous: false
  separate_value_head: true
training:
  algorithm: ppo
  max_epochs: 50
  learning_rate: 0.0001
  mixed_precision: "no"
data:
  batch_size: 128
  num_samples: 10000
  seq_len: 64
